{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Rcpp\n",
      "\n",
      "Loading 'brms' package (version 2.18.0). Useful instructions\n",
      "can be found by typing help('brms'). A more detailed introduction\n",
      "to the package is available through vignette('brms_overview').\n",
      "\n",
      "\n",
      "Attaching package: ‘brms’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    ar\n",
      "\n",
      "\n",
      "This is lavaan 0.6-14\n",
      "lavaan is FREE software! Please report any bugs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(brms)\n",
    "library(lavaan)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "N <- 100\n",
    "M <- 2\n",
    "K <- 4\n",
    "J <- 3\n",
    "\n",
    "mu <- 0\n",
    "al <- matrix(c(-1, 1), ncol = 1)\n",
    "Z <- matrix(rnorm(M*N), ncol = N)\n",
    "ep_x <- matrix(rnorm(N, sd = 0.1), ncol = N)\n",
    "X <- t(al) %*% Z + ep_x\n",
    "\n",
    "U <- matrix(rnorm(K*N, sd = .2), ncol = N)\n",
    "W <- sweep(U, 2, X, \"+\")\n",
    "\n",
    "h_1 <- function(x) x^2\n",
    "h_2 <- function(x) -x^2\n",
    "f <- function(x) x^3\n",
    "eta <- rnorm(N)\n",
    "S <- f(X) + h_1(Z[1, ]) + h_2(Z[2, ]) + eta\n",
    "S <- matrix(S, ncol = N)\n",
    "\n",
    "beta0 <- matrix(rep(0, J*N), ncol = N)\n",
    "beta1 <- matrix(rep(2, J), ncol = 1)\n",
    "ep_y <- matrix(rnorm(J * N, sd = 0.1), ncol = N)\n",
    "Y <- beta0 + beta1 %*% S + ep_y\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying brms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in model.frame.default(x$respform, data): invalid type (list) for variable 's(mi(X))'\n",
     "output_type": "error",
     "traceback": [
      "Error in model.frame.default(x$respform, data): invalid type (list) for variable 's(mi(X))'\nTraceback:\n",
      "1. brm(bf1 + bf2 + bf3 + bf4 + bf5 + bf6 + bf7 + bf8 + bf9 + bf10 + \n .     bf11 + bf12 + bf13 + bf14 + set_rescor(FALSE), data = data, \n .     family = gaussian(), iter = 2000, chains = 2, cores = 4, \n .     seed = 123, prior = c(prior(normal(1, 0.1), coef = miX, resp = W1), \n .         prior(normal(1, 0.1), coef = miX, resp = W2), prior(normal(1, \n .             0.1), coef = miX, resp = W3), prior(normal(1, 0.1), \n .             coef = miX, resp = W4)))",
      "2. .validate_prior(prior, bterms = bterms, data = data, sample_prior = sample_prior)",
      "3. .get_prior(bterms, data, internal = TRUE)",
      "4. prior_predictor(bterms, data = data, internal = internal)",
      "5. prior_predictor.mvbrmsterms(bterms, data = data, internal = internal)",
      "6. prior_predictor(x$terms[[i]], ...)",
      "7. prior_predictor.brmsterms(x$terms[[i]], ...)",
      "8. def_scale_prior(x, data)",
      "9. def_scale_prior.brmsterms(x, data)",
      "10. unname(model.response(model.frame(x$respform, data)))",
      "11. model.response(model.frame(x$respform, data))",
      "12. model.frame(x$respform, data)",
      "13. model.frame.default(x$respform, data)"
     ]
    }
   ],
   "source": [
    "data <- as.data.frame(t(rbind(Z,W,Y)))\n",
    "names(data) <- c(\"Z1\", \"Z2\", \"W1\", \"W2\", \"W3\", \"W4\", \"Y1\", \"Y2\", \"Y3\")\n",
    "\n",
    "data$S <- as.numeric(NA)\n",
    "data$X <- as.numeric(NA)\n",
    "\n",
    "bf1 <- bf(Z1 ~ 0 + mi(X))\n",
    "bf2 <- bf(Z2 ~ 0 + mi(X))\n",
    "bf3 <- bf(X | mi() ~ 0)\n",
    "bf4 <- bf(W1 ~ 0 + mi(X))\n",
    "bf5 <- bf(W2 ~ 0 + mi(X))\n",
    "bf6 <- bf(W3 ~ 0 + mi(X))\n",
    "bf7 <- bf(W4 ~ 0 + mi(X))\n",
    "bf8 <- bf(s(mi(X)) ~ 0 + mi(S))\n",
    "bf9 <- bf(s(Z1) ~ 0 + mi(S))\n",
    "bf10 <- bf(s(Z2) ~ 0 + mi(S))\n",
    "bf11 <- bf(S | mi() ~ 0)\n",
    "bf12 <- bf(Y1 ~ 0 + mi(S))\n",
    "bf13 <- bf(Y2 ~ 0 + mi(S))\n",
    "bf14 <- bf(Y3 ~ 0 + mi(S))\n",
    "\n",
    "model <- brm(bf1 + bf2 + bf3 + bf4 + bf5 + bf6 + bf7 + bf8 + bf9 + \n",
    "bf10 + bf11 + bf12 + bf13 + bf14 + set_rescor(FALSE), data = data, family = gaussian(), \n",
    "iter = 2000, chains = 2, cores = 4, seed = 123,\n",
    "prior = c(prior(normal(1, 0000.1), coef = miX, resp = W1), \n",
    "prior(normal(1, 0000.1), coef = miX, resp = W2),\n",
    "prior(normal(1, 0000.1), coef = miX, resp = W3),\n",
    "prior(normal(1, 0000.1), coef = miX, resp = W4)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in model.frame.default(x$respform, data): invalid type (list) for variable 's(X)'\n",
     "output_type": "error",
     "traceback": [
      "Error in model.frame.default(x$respform, data): invalid type (list) for variable 's(X)'\nTraceback:\n",
      "1. brm(bf1 + bf2 + bf3 + bf4 + bf5 + bf6 + bf7 + bf8 + bf9 + bf10 + \n .     bf11 + bf12 + bf13 + bf14 + set_rescor(FALSE), data = data, \n .     family = gaussian(), iter = 2000, chains = 2, cores = 4, \n .     seed = 123, prior = c(prior(normal(1, 0.1), coef = miX, resp = W1), \n .         prior(normal(1, 0.1), coef = miX, resp = W2), prior(normal(1, \n .             0.1), coef = miX, resp = W3), prior(normal(1, 0.1), \n .             coef = miX, resp = W4)))",
      "2. .validate_prior(prior, bterms = bterms, data = data, sample_prior = sample_prior)",
      "3. .get_prior(bterms, data, internal = TRUE)",
      "4. prior_predictor(bterms, data = data, internal = internal)",
      "5. prior_predictor.mvbrmsterms(bterms, data = data, internal = internal)",
      "6. prior_predictor(x$terms[[i]], ...)",
      "7. prior_predictor.brmsterms(x$terms[[i]], ...)",
      "8. def_scale_prior(x, data)",
      "9. def_scale_prior.brmsterms(x, data)",
      "10. unname(model.response(model.frame(x$respform, data)))",
      "11. model.response(model.frame(x$respform, data))",
      "12. model.frame(x$respform, data)",
      "13. model.frame.default(x$respform, data)"
     ]
    }
   ],
   "source": [
    "bf1 <- bf(Z1 ~ 0 + mi(X))\n",
    "bf2 <- bf(Z2 ~ 0 + mi(X))\n",
    "bf3 <- bf(X | mi() ~ 0)\n",
    "bf4 <- bf(W1 ~ 0 + mi(X))\n",
    "bf5 <- bf(W2 ~ 0 + mi(X))\n",
    "bf6 <- bf(W3 ~ 0 + mi(X))\n",
    "bf7 <- bf(W4 ~ 0 + mi(X))\n",
    "bf8 <- bf(s(X) ~ 0 + mi(S) )\n",
    "bf9 <- bf(s(Z1) ~ 0 + mi(S))\n",
    "bf10 <- bf(s(Z2) ~ 0 + mi(S))\n",
    "bf11 <- bf(S | mi() ~ 0)\n",
    "bf12 <- bf(Y1 ~ 0 + mi(S))\n",
    "bf13 <- bf(Y2 ~ 0 + mi(S))\n",
    "bf14 <- bf(Y3 ~ 0 + mi(S))\n",
    "\n",
    "model <- brm(bf1 + bf2 + bf3 + bf4 + bf5 + bf6 + bf7 + bf8 + bf9 + \n",
    "bf10 + bf11 + bf12 + bf13 + bf14 + set_rescor(FALSE), data = data, family = gaussian(), \n",
    "iter = 2000, chains = 2, cores = 4, seed = 123,\n",
    "prior = c(prior(normal(1, 0000.1), coef = miX, resp = W1), \n",
    "prior(normal(1, 0000.1), coef = miX, resp = W2),\n",
    "prior(normal(1, 0000.1), coef = miX, resp = W3),\n",
    "prior(normal(1, 0000.1), coef = miX, resp = W4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in model.frame.default(x$respform, data): invalid type (list) for variable 'mi(X)'\n",
     "output_type": "error",
     "traceback": [
      "Error in model.frame.default(x$respform, data): invalid type (list) for variable 'mi(X)'\nTraceback:\n",
      "1. brm(bf1 + bf2 + bf3 + bf4 + bf5 + bf6 + bf7 + bf8 + bf9 + bf10 + \n .     bf11 + bf12 + bf13 + bf14 + set_rescor(FALSE), data = data, \n .     family = gaussian(), iter = 2000, chains = 2, cores = 4, \n .     seed = 123, prior = c(prior(normal(1, 0.1), coef = miX, resp = W1), \n .         prior(normal(1, 0.1), coef = miX, resp = W2), prior(normal(1, \n .             0.1), coef = miX, resp = W3), prior(normal(1, 0.1), \n .             coef = miX, resp = W4)))",
      "2. .validate_prior(prior, bterms = bterms, data = data, sample_prior = sample_prior)",
      "3. .get_prior(bterms, data, internal = TRUE)",
      "4. prior_predictor(bterms, data = data, internal = internal)",
      "5. prior_predictor.mvbrmsterms(bterms, data = data, internal = internal)",
      "6. prior_predictor(x$terms[[i]], ...)",
      "7. prior_predictor.brmsterms(x$terms[[i]], ...)",
      "8. def_scale_prior(x, data)",
      "9. def_scale_prior.brmsterms(x, data)",
      "10. unname(model.response(model.frame(x$respform, data)))",
      "11. model.response(model.frame(x$respform, data))",
      "12. model.frame(x$respform, data)",
      "13. model.frame.default(x$respform, data)"
     ]
    }
   ],
   "source": [
    "bf1 <- bf(Z1 ~ 0 + mi(X))\n",
    "bf2 <- bf(Z2 ~ 0 + mi(X))\n",
    "bf3 <- bf(X | mi() ~ 0)\n",
    "bf4 <- bf(W1 ~ 0 + mi(X))\n",
    "bf5 <- bf(W2 ~ 0 + mi(X))\n",
    "bf6 <- bf(W3 ~ 0 + mi(X))\n",
    "bf7 <- bf(W4 ~ 0 + mi(X))\n",
    "bf8 <- bf(mi(X) ~ 0 + mi(S) )\n",
    "bf9 <- bf(s(Z1) ~ 0 + mi(S))\n",
    "bf10 <- bf(s(Z2) ~ 0 + mi(S))\n",
    "bf11 <- bf(S | mi() ~ 0)\n",
    "bf12 <- bf(Y1 ~ 0 + mi(S))\n",
    "bf13 <- bf(Y2 ~ 0 + mi(S))\n",
    "bf14 <- bf(Y3 ~ 0 + mi(S))\n",
    "\n",
    "model <- brm(bf1 + bf2 + bf3 + bf4 + bf5 + bf6 + bf7 + bf8 + bf9 + \n",
    "bf10 + bf11 + bf12 + bf13 + bf14 + set_rescor(FALSE), data = data, family = gaussian(), \n",
    "iter = 2000, chains = 2, cores = 4, seed = 123,\n",
    "prior = c(prior(normal(1, 0000.1), coef = miX, resp = W1), \n",
    "prior(normal(1, 0000.1), coef = miX, resp = W2),\n",
    "prior(normal(1, 0000.1), coef = miX, resp = W3),\n",
    "prior(normal(1, 0000.1), coef = miX, resp = W4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: Cannot use the same response variable twice in the same model.\n",
     "output_type": "error",
     "traceback": [
      "Error: Cannot use the same response variable twice in the same model.\nTraceback:\n",
      "1. brm(bf1 + bf2 + bf3 + bf4 + bf5 + bf6 + bf7 + bf8 + bf9 + bf10 + \n .     bf11 + bf12 + bf13 + bf14 + set_rescor(FALSE), data = data, \n .     family = gaussian(), iter = 2000, chains = 2, cores = 4, \n .     seed = 123, prior = c(prior(normal(1, 0.1), coef = miX, resp = W1), \n .         prior(normal(1, 0.1), coef = miX, resp = W2), prior(normal(1, \n .             0.1), coef = miX, resp = W3), prior(normal(1, 0.1), \n .             coef = miX, resp = W4)))",
      "2. validate_formula(formula, data = data, family = family, autocor = autocor, \n .     sparse = sparse, cov_ranef = cov_ranef)",
      "3. `+.bform`(bf1 + bf2 + bf3 + bf4 + bf5 + bf6 + bf7, bf8)",
      "4. plus_mvbrmsformula(e1, e2)",
      "5. mvbf(e1, e2)",
      "6. mvbrmsformula(..., flist = flist, rescor = rescor)",
      "7. stop2(\"Cannot use the same response variable twice in the same model.\")",
      "8. stop(..., call. = FALSE)"
     ]
    }
   ],
   "source": [
    "bf1 <- bf(Z1 ~ 0 + mi(X))\n",
    "bf2 <- bf(Z2 ~ 0 + mi(X))\n",
    "bf3 <- bf(X | mi() ~ 0)\n",
    "bf4 <- bf(W1 ~ 0 + mi(X))\n",
    "bf5 <- bf(W2 ~ 0 + mi(X))\n",
    "bf6 <- bf(W3 ~ 0 + mi(X))\n",
    "bf7 <- bf(W4 ~ 0 + mi(X))\n",
    "bf8 <- bf(X ~ 0 + mi(S) )\n",
    "bf9 <- bf(s(Z1) ~ 0 + mi(S))\n",
    "bf10 <- bf(s(Z2) ~ 0 + mi(S))\n",
    "bf11 <- bf(S | mi() ~ 0)\n",
    "bf12 <- bf(Y1 ~ 0 + mi(S))\n",
    "bf13 <- bf(Y2 ~ 0 + mi(S))\n",
    "bf14 <- bf(Y3 ~ 0 + mi(S))\n",
    "\n",
    "model <- brm(bf1 + bf2 + bf3 + bf4 + bf5 + bf6 + bf7 + bf8 + bf9 + \n",
    "bf10 + bf11 + bf12 + bf13 + bf14 + set_rescor(FALSE), data = data, family = gaussian(), \n",
    "iter = 2000, chains = 2, cores = 4, seed = 123,\n",
    "prior = c(prior(normal(1, 0000.1), coef = miX, resp = W1), \n",
    "prior(normal(1, 0000.1), coef = miX, resp = W2),\n",
    "prior(normal(1, 0000.1), coef = miX, resp = W3),\n",
    "prior(normal(1, 0000.1), coef = miX, resp = W4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: Cannot use the same response variable twice in the same model.\n",
     "output_type": "error",
     "traceback": [
      "Error: Cannot use the same response variable twice in the same model.\nTraceback:\n",
      "1. brm(bf1 + bf2 + bf3 + bf4 + bf5 + bf6 + bf7 + bf8 + bf9 + bf10 + \n .     bf11 + bf12 + bf13 + bf14 + set_rescor(FALSE), data = data, \n .     family = gaussian(), iter = 2000, chains = 2, cores = 4, \n .     seed = 123, prior = c(prior(normal(1, 0.1), coef = miX, resp = W1), \n .         prior(normal(1, 0.1), coef = miX, resp = W2), prior(normal(1, \n .             0.1), coef = miX, resp = W3), prior(normal(1, 0.1), \n .             coef = miX, resp = W4)))",
      "2. validate_formula(formula, data = data, family = family, autocor = autocor, \n .     sparse = sparse, cov_ranef = cov_ranef)",
      "3. `+.bform`(bf1 + bf2 + bf3 + bf4 + bf5 + bf6 + bf7, bf8)",
      "4. plus_mvbrmsformula(e1, e2)",
      "5. mvbf(e1, e2)",
      "6. mvbrmsformula(..., flist = flist, rescor = rescor)",
      "7. stop2(\"Cannot use the same response variable twice in the same model.\")",
      "8. stop(..., call. = FALSE)"
     ]
    }
   ],
   "source": [
    "bf1 <- bf(Z1 ~ 0 + mi(X))\n",
    "bf2 <- bf(Z2 ~ 0 + mi(X))\n",
    "bf3 <- bf(X | mi() ~ 0)\n",
    "bf4 <- bf(W1 ~ 0 + mi(X))\n",
    "bf5 <- bf(W2 ~ 0 + mi(X))\n",
    "bf6 <- bf(W3 ~ 0 + mi(X))\n",
    "bf7 <- bf(W4 ~ 0 + mi(X))\n",
    "bf8 <- bf(X |mi() ~ 0 + mi(S) )\n",
    "bf9 <- bf(s(Z1) ~ 0 + mi(S))\n",
    "bf10 <- bf(s(Z2) ~ 0 + mi(S))\n",
    "bf11 <- bf(S | mi() ~ 0)\n",
    "bf12 <- bf(Y1 ~ 0 + mi(S))\n",
    "bf13 <- bf(Y2 ~ 0 + mi(S))\n",
    "bf14 <- bf(Y3 ~ 0 + mi(S))\n",
    "\n",
    "model <- brm(bf1 + bf2 + bf3 + bf4 + bf5 + bf6 + bf7 + bf8 + bf9 + \n",
    "bf10 + bf11 + bf12 + bf13 + bf14 + set_rescor(FALSE), data = data, family = gaussian(), \n",
    "iter = 2000, chains = 2, cores = 4, seed = 123,\n",
    "prior = c(prior(normal(1, 0000.1), coef = miX, resp = W1), \n",
    "prior(normal(1, 0000.1), coef = miX, resp = W2),\n",
    "prior(normal(1, 0000.1), coef = miX, resp = W3),\n",
    "prior(normal(1, 0000.1), coef = miX, resp = W4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in model.frame.default(x$respform, data): invalid type (list) for variable 's(X)'\n",
     "output_type": "error",
     "traceback": [
      "Error in model.frame.default(x$respform, data): invalid type (list) for variable 's(X)'\nTraceback:\n",
      "1. brm(bf1 + bf2 + bf3 + bf4 + bf5 + bf6 + bf7 + bf8 + bf9 + bf10 + \n .     bf11 + bf12 + bf13 + bf14 + set_rescor(FALSE), data = data, \n .     family = gaussian(), iter = 2000, chains = 2, cores = 4, \n .     seed = 123, prior = c(prior(normal(1, 0.1), coef = miX, resp = W1), \n .         prior(normal(1, 0.1), coef = miX, resp = W2), prior(normal(1, \n .             0.1), coef = miX, resp = W3), prior(normal(1, 0.1), \n .             coef = miX, resp = W4)))",
      "2. .validate_prior(prior, bterms = bterms, data = data, sample_prior = sample_prior)",
      "3. .get_prior(bterms, data, internal = TRUE)",
      "4. prior_predictor(bterms, data = data, internal = internal)",
      "5. prior_predictor.mvbrmsterms(bterms, data = data, internal = internal)",
      "6. prior_predictor(x$terms[[i]], ...)",
      "7. prior_predictor.brmsterms(x$terms[[i]], ...)",
      "8. def_scale_prior(x, data)",
      "9. def_scale_prior.brmsterms(x, data)",
      "10. unname(model.response(model.frame(x$respform, data)))",
      "11. model.response(model.frame(x$respform, data))",
      "12. model.frame(x$respform, data)",
      "13. model.frame.default(x$respform, data)"
     ]
    }
   ],
   "source": [
    "bf1 <- bf(Z1 ~ 0 + mi(X))\n",
    "bf2 <- bf(Z2 ~ 0 + mi(X))\n",
    "bf3 <- bf(X | mi() ~ 0)\n",
    "bf4 <- bf(W1 ~ 0 + mi(X))\n",
    "bf5 <- bf(W2 ~ 0 + mi(X))\n",
    "bf6 <- bf(W3 ~ 0 + mi(X))\n",
    "bf7 <- bf(W4 ~ 0 + mi(X))\n",
    "bf8 <- bf(s(X) |mi() ~ 0 + mi(S) )\n",
    "bf9 <- bf(s(Z1) ~ 0 + mi(S))\n",
    "bf10 <- bf(s(Z2) ~ 0 + mi(S))\n",
    "bf11 <- bf(S | mi() ~ 0)\n",
    "bf12 <- bf(Y1 ~ 0 + mi(S))\n",
    "bf13 <- bf(Y2 ~ 0 + mi(S))\n",
    "bf14 <- bf(Y3 ~ 0 + mi(S))\n",
    "\n",
    "model <- brm(bf1 + bf2 + bf3 + bf4 + bf5 + bf6 + bf7 + bf8 + bf9 + \n",
    "bf10 + bf11 + bf12 + bf13 + bf14 + set_rescor(FALSE), data = data, family = gaussian(), \n",
    "iter = 2000, chains = 2, cores = 4, seed = 123,\n",
    "prior = c(prior(normal(1, 0000.1), coef = miX, resp = W1), \n",
    "prior(normal(1, 0000.1), coef = miX, resp = W2),\n",
    "prior(normal(1, 0000.1), coef = miX, resp = W3),\n",
    "prior(normal(1, 0000.1), coef = miX, resp = W4)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lavaan, for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in lavaan::lavaan(model = mod, data = data, model.type = \"sem\", :\n",
      "“lavaan WARNING:\n",
      "    the optimizer warns that a solution has NOT been found!”\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A lavaan.data.frame: 44 × 9</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>lhs</th><th scope=col>op</th><th scope=col>rhs</th><th scope=col>est</th><th scope=col>se</th><th scope=col>z</th><th scope=col>pvalue</th><th scope=col>ci.lower</th><th scope=col>ci.upper</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Xl</td><td>=~</td><td>Z1</td><td> 1.000000e+00</td><td> 0</td><td>NA</td><td>NA</td><td> 1</td><td> 1</td></tr>\n",
       "\t<tr><td>Xl</td><td>=~</td><td>Z2</td><td> 9.954292e+01</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W1</td><td>~ </td><td>Xl</td><td> 1.000000e+00</td><td> 0</td><td>NA</td><td>NA</td><td> 1</td><td> 1</td></tr>\n",
       "\t<tr><td>W2</td><td>~ </td><td>Xl</td><td> 1.000000e+00</td><td> 0</td><td>NA</td><td>NA</td><td> 1</td><td> 1</td></tr>\n",
       "\t<tr><td>W3</td><td>~ </td><td>Xl</td><td> 1.000000e+00</td><td> 0</td><td>NA</td><td>NA</td><td> 1</td><td> 1</td></tr>\n",
       "\t<tr><td>W4</td><td>~ </td><td>Xl</td><td> 1.000000e+00</td><td> 0</td><td>NA</td><td>NA</td><td> 1</td><td> 1</td></tr>\n",
       "\t<tr><td>Sl</td><td>=~</td><td>Xl</td><td> 1.000000e+00</td><td> 0</td><td>NA</td><td>NA</td><td> 1</td><td> 1</td></tr>\n",
       "\t<tr><td>Sl</td><td>=~</td><td>Z1</td><td> 1.000000e+00</td><td> 0</td><td>NA</td><td>NA</td><td> 1</td><td> 1</td></tr>\n",
       "\t<tr><td>Sl</td><td>=~</td><td>Z2</td><td> 1.000000e+00</td><td> 0</td><td>NA</td><td>NA</td><td> 1</td><td> 1</td></tr>\n",
       "\t<tr><td>Y1</td><td>~ </td><td>Sl</td><td>-5.013969e+04</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>Y2</td><td>~ </td><td>Sl</td><td>-5.008239e+04</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>Y3</td><td>~ </td><td>Sl</td><td>-5.012076e+04</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>Z1</td><td>~~</td><td>Z1</td><td> 1.517355e+00</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>Z2</td><td>~~</td><td>Z2</td><td>-1.495842e+02</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W1</td><td>~~</td><td>W1</td><td> 1.583656e+00</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W2</td><td>~~</td><td>W2</td><td> 1.555718e+00</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W3</td><td>~~</td><td>W3</td><td> 1.574713e+00</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W4</td><td>~~</td><td>W4</td><td> 1.572310e+00</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>Y1</td><td>~~</td><td>Y1</td><td> 9.449065e+03</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>Y2</td><td>~~</td><td>Y2</td><td> 9.427715e+03</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>Y3</td><td>~~</td><td>Y3</td><td> 9.442074e+03</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>Xl</td><td>~~</td><td>Xl</td><td> 1.540572e-02</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>Sl</td><td>~~</td><td>Sl</td><td>-3.614910e-06</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W1</td><td>~~</td><td>W2</td><td> 1.533910e+00</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W1</td><td>~~</td><td>W3</td><td> 1.537922e+00</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W1</td><td>~~</td><td>W4</td><td> 1.534279e+00</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W1</td><td>~~</td><td>Y1</td><td> 1.831594e+01</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W1</td><td>~~</td><td>Y2</td><td> 1.829617e+01</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W1</td><td>~~</td><td>Y3</td><td> 1.830570e+01</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W2</td><td>~~</td><td>W3</td><td> 1.530534e+00</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W2</td><td>~~</td><td>W4</td><td> 1.532390e+00</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W2</td><td>~~</td><td>Y1</td><td> 1.831280e+01</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W2</td><td>~~</td><td>Y2</td><td> 1.829696e+01</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W2</td><td>~~</td><td>Y3</td><td> 1.830682e+01</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W3</td><td>~~</td><td>W4</td><td> 1.536834e+00</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W3</td><td>~~</td><td>Y1</td><td> 1.867649e+01</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W3</td><td>~~</td><td>Y2</td><td> 1.865395e+01</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W3</td><td>~~</td><td>Y3</td><td> 1.866652e+01</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W4</td><td>~~</td><td>Y1</td><td> 1.844548e+01</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W4</td><td>~~</td><td>Y2</td><td> 1.842872e+01</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>W4</td><td>~~</td><td>Y3</td><td> 1.843657e+01</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>Y1</td><td>~~</td><td>Y2</td><td> 9.438374e+03</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>Y1</td><td>~~</td><td>Y3</td><td> 9.445559e+03</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><td>Y2</td><td>~~</td><td>Y3</td><td> 9.434882e+03</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A lavaan.data.frame: 44 × 9\n",
       "\\begin{tabular}{lllllllll}\n",
       " lhs & op & rhs & est & se & z & pvalue & ci.lower & ci.upper\\\\\n",
       " <chr> & <chr> & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t Xl & =\\textasciitilde{} & Z1 &  1.000000e+00 &  0 & NA & NA &  1 &  1\\\\\n",
       "\t Xl & =\\textasciitilde{} & Z2 &  9.954292e+01 & NA & NA & NA & NA & NA\\\\\n",
       "\t W1 & \\textasciitilde{}  & Xl &  1.000000e+00 &  0 & NA & NA &  1 &  1\\\\\n",
       "\t W2 & \\textasciitilde{}  & Xl &  1.000000e+00 &  0 & NA & NA &  1 &  1\\\\\n",
       "\t W3 & \\textasciitilde{}  & Xl &  1.000000e+00 &  0 & NA & NA &  1 &  1\\\\\n",
       "\t W4 & \\textasciitilde{}  & Xl &  1.000000e+00 &  0 & NA & NA &  1 &  1\\\\\n",
       "\t Sl & =\\textasciitilde{} & Xl &  1.000000e+00 &  0 & NA & NA &  1 &  1\\\\\n",
       "\t Sl & =\\textasciitilde{} & Z1 &  1.000000e+00 &  0 & NA & NA &  1 &  1\\\\\n",
       "\t Sl & =\\textasciitilde{} & Z2 &  1.000000e+00 &  0 & NA & NA &  1 &  1\\\\\n",
       "\t Y1 & \\textasciitilde{}  & Sl & -5.013969e+04 & NA & NA & NA & NA & NA\\\\\n",
       "\t Y2 & \\textasciitilde{}  & Sl & -5.008239e+04 & NA & NA & NA & NA & NA\\\\\n",
       "\t Y3 & \\textasciitilde{}  & Sl & -5.012076e+04 & NA & NA & NA & NA & NA\\\\\n",
       "\t Z1 & \\textasciitilde{}\\textasciitilde{} & Z1 &  1.517355e+00 & NA & NA & NA & NA & NA\\\\\n",
       "\t Z2 & \\textasciitilde{}\\textasciitilde{} & Z2 & -1.495842e+02 & NA & NA & NA & NA & NA\\\\\n",
       "\t W1 & \\textasciitilde{}\\textasciitilde{} & W1 &  1.583656e+00 & NA & NA & NA & NA & NA\\\\\n",
       "\t W2 & \\textasciitilde{}\\textasciitilde{} & W2 &  1.555718e+00 & NA & NA & NA & NA & NA\\\\\n",
       "\t W3 & \\textasciitilde{}\\textasciitilde{} & W3 &  1.574713e+00 & NA & NA & NA & NA & NA\\\\\n",
       "\t W4 & \\textasciitilde{}\\textasciitilde{} & W4 &  1.572310e+00 & NA & NA & NA & NA & NA\\\\\n",
       "\t Y1 & \\textasciitilde{}\\textasciitilde{} & Y1 &  9.449065e+03 & NA & NA & NA & NA & NA\\\\\n",
       "\t Y2 & \\textasciitilde{}\\textasciitilde{} & Y2 &  9.427715e+03 & NA & NA & NA & NA & NA\\\\\n",
       "\t Y3 & \\textasciitilde{}\\textasciitilde{} & Y3 &  9.442074e+03 & NA & NA & NA & NA & NA\\\\\n",
       "\t Xl & \\textasciitilde{}\\textasciitilde{} & Xl &  1.540572e-02 & NA & NA & NA & NA & NA\\\\\n",
       "\t Sl & \\textasciitilde{}\\textasciitilde{} & Sl & -3.614910e-06 & NA & NA & NA & NA & NA\\\\\n",
       "\t W1 & \\textasciitilde{}\\textasciitilde{} & W2 &  1.533910e+00 & NA & NA & NA & NA & NA\\\\\n",
       "\t W1 & \\textasciitilde{}\\textasciitilde{} & W3 &  1.537922e+00 & NA & NA & NA & NA & NA\\\\\n",
       "\t W1 & \\textasciitilde{}\\textasciitilde{} & W4 &  1.534279e+00 & NA & NA & NA & NA & NA\\\\\n",
       "\t W1 & \\textasciitilde{}\\textasciitilde{} & Y1 &  1.831594e+01 & NA & NA & NA & NA & NA\\\\\n",
       "\t W1 & \\textasciitilde{}\\textasciitilde{} & Y2 &  1.829617e+01 & NA & NA & NA & NA & NA\\\\\n",
       "\t W1 & \\textasciitilde{}\\textasciitilde{} & Y3 &  1.830570e+01 & NA & NA & NA & NA & NA\\\\\n",
       "\t W2 & \\textasciitilde{}\\textasciitilde{} & W3 &  1.530534e+00 & NA & NA & NA & NA & NA\\\\\n",
       "\t W2 & \\textasciitilde{}\\textasciitilde{} & W4 &  1.532390e+00 & NA & NA & NA & NA & NA\\\\\n",
       "\t W2 & \\textasciitilde{}\\textasciitilde{} & Y1 &  1.831280e+01 & NA & NA & NA & NA & NA\\\\\n",
       "\t W2 & \\textasciitilde{}\\textasciitilde{} & Y2 &  1.829696e+01 & NA & NA & NA & NA & NA\\\\\n",
       "\t W2 & \\textasciitilde{}\\textasciitilde{} & Y3 &  1.830682e+01 & NA & NA & NA & NA & NA\\\\\n",
       "\t W3 & \\textasciitilde{}\\textasciitilde{} & W4 &  1.536834e+00 & NA & NA & NA & NA & NA\\\\\n",
       "\t W3 & \\textasciitilde{}\\textasciitilde{} & Y1 &  1.867649e+01 & NA & NA & NA & NA & NA\\\\\n",
       "\t W3 & \\textasciitilde{}\\textasciitilde{} & Y2 &  1.865395e+01 & NA & NA & NA & NA & NA\\\\\n",
       "\t W3 & \\textasciitilde{}\\textasciitilde{} & Y3 &  1.866652e+01 & NA & NA & NA & NA & NA\\\\\n",
       "\t W4 & \\textasciitilde{}\\textasciitilde{} & Y1 &  1.844548e+01 & NA & NA & NA & NA & NA\\\\\n",
       "\t W4 & \\textasciitilde{}\\textasciitilde{} & Y2 &  1.842872e+01 & NA & NA & NA & NA & NA\\\\\n",
       "\t W4 & \\textasciitilde{}\\textasciitilde{} & Y3 &  1.843657e+01 & NA & NA & NA & NA & NA\\\\\n",
       "\t Y1 & \\textasciitilde{}\\textasciitilde{} & Y2 &  9.438374e+03 & NA & NA & NA & NA & NA\\\\\n",
       "\t Y1 & \\textasciitilde{}\\textasciitilde{} & Y3 &  9.445559e+03 & NA & NA & NA & NA & NA\\\\\n",
       "\t Y2 & \\textasciitilde{}\\textasciitilde{} & Y3 &  9.434882e+03 & NA & NA & NA & NA & NA\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A lavaan.data.frame: 44 × 9\n",
       "\n",
       "| lhs &lt;chr&gt; | op &lt;chr&gt; | rhs &lt;chr&gt; | est &lt;dbl&gt; | se &lt;dbl&gt; | z &lt;dbl&gt; | pvalue &lt;dbl&gt; | ci.lower &lt;dbl&gt; | ci.upper &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| Xl | =~ | Z1 |  1.000000e+00 |  0 | NA | NA |  1 |  1 |\n",
       "| Xl | =~ | Z2 |  9.954292e+01 | NA | NA | NA | NA | NA |\n",
       "| W1 | ~  | Xl |  1.000000e+00 |  0 | NA | NA |  1 |  1 |\n",
       "| W2 | ~  | Xl |  1.000000e+00 |  0 | NA | NA |  1 |  1 |\n",
       "| W3 | ~  | Xl |  1.000000e+00 |  0 | NA | NA |  1 |  1 |\n",
       "| W4 | ~  | Xl |  1.000000e+00 |  0 | NA | NA |  1 |  1 |\n",
       "| Sl | =~ | Xl |  1.000000e+00 |  0 | NA | NA |  1 |  1 |\n",
       "| Sl | =~ | Z1 |  1.000000e+00 |  0 | NA | NA |  1 |  1 |\n",
       "| Sl | =~ | Z2 |  1.000000e+00 |  0 | NA | NA |  1 |  1 |\n",
       "| Y1 | ~  | Sl | -5.013969e+04 | NA | NA | NA | NA | NA |\n",
       "| Y2 | ~  | Sl | -5.008239e+04 | NA | NA | NA | NA | NA |\n",
       "| Y3 | ~  | Sl | -5.012076e+04 | NA | NA | NA | NA | NA |\n",
       "| Z1 | ~~ | Z1 |  1.517355e+00 | NA | NA | NA | NA | NA |\n",
       "| Z2 | ~~ | Z2 | -1.495842e+02 | NA | NA | NA | NA | NA |\n",
       "| W1 | ~~ | W1 |  1.583656e+00 | NA | NA | NA | NA | NA |\n",
       "| W2 | ~~ | W2 |  1.555718e+00 | NA | NA | NA | NA | NA |\n",
       "| W3 | ~~ | W3 |  1.574713e+00 | NA | NA | NA | NA | NA |\n",
       "| W4 | ~~ | W4 |  1.572310e+00 | NA | NA | NA | NA | NA |\n",
       "| Y1 | ~~ | Y1 |  9.449065e+03 | NA | NA | NA | NA | NA |\n",
       "| Y2 | ~~ | Y2 |  9.427715e+03 | NA | NA | NA | NA | NA |\n",
       "| Y3 | ~~ | Y3 |  9.442074e+03 | NA | NA | NA | NA | NA |\n",
       "| Xl | ~~ | Xl |  1.540572e-02 | NA | NA | NA | NA | NA |\n",
       "| Sl | ~~ | Sl | -3.614910e-06 | NA | NA | NA | NA | NA |\n",
       "| W1 | ~~ | W2 |  1.533910e+00 | NA | NA | NA | NA | NA |\n",
       "| W1 | ~~ | W3 |  1.537922e+00 | NA | NA | NA | NA | NA |\n",
       "| W1 | ~~ | W4 |  1.534279e+00 | NA | NA | NA | NA | NA |\n",
       "| W1 | ~~ | Y1 |  1.831594e+01 | NA | NA | NA | NA | NA |\n",
       "| W1 | ~~ | Y2 |  1.829617e+01 | NA | NA | NA | NA | NA |\n",
       "| W1 | ~~ | Y3 |  1.830570e+01 | NA | NA | NA | NA | NA |\n",
       "| W2 | ~~ | W3 |  1.530534e+00 | NA | NA | NA | NA | NA |\n",
       "| W2 | ~~ | W4 |  1.532390e+00 | NA | NA | NA | NA | NA |\n",
       "| W2 | ~~ | Y1 |  1.831280e+01 | NA | NA | NA | NA | NA |\n",
       "| W2 | ~~ | Y2 |  1.829696e+01 | NA | NA | NA | NA | NA |\n",
       "| W2 | ~~ | Y3 |  1.830682e+01 | NA | NA | NA | NA | NA |\n",
       "| W3 | ~~ | W4 |  1.536834e+00 | NA | NA | NA | NA | NA |\n",
       "| W3 | ~~ | Y1 |  1.867649e+01 | NA | NA | NA | NA | NA |\n",
       "| W3 | ~~ | Y2 |  1.865395e+01 | NA | NA | NA | NA | NA |\n",
       "| W3 | ~~ | Y3 |  1.866652e+01 | NA | NA | NA | NA | NA |\n",
       "| W4 | ~~ | Y1 |  1.844548e+01 | NA | NA | NA | NA | NA |\n",
       "| W4 | ~~ | Y2 |  1.842872e+01 | NA | NA | NA | NA | NA |\n",
       "| W4 | ~~ | Y3 |  1.843657e+01 | NA | NA | NA | NA | NA |\n",
       "| Y1 | ~~ | Y2 |  9.438374e+03 | NA | NA | NA | NA | NA |\n",
       "| Y1 | ~~ | Y3 |  9.445559e+03 | NA | NA | NA | NA | NA |\n",
       "| Y2 | ~~ | Y3 |  9.434882e+03 | NA | NA | NA | NA | NA |\n",
       "\n"
      ],
      "text/plain": [
       "   lhs op rhs est           se z  pvalue ci.lower ci.upper\n",
       "1  Xl  =~ Z1   1.000000e+00  0 NA NA      1        1      \n",
       "2  Xl  =~ Z2   9.954292e+01 NA NA NA     NA       NA      \n",
       "3  W1  ~  Xl   1.000000e+00  0 NA NA      1        1      \n",
       "4  W2  ~  Xl   1.000000e+00  0 NA NA      1        1      \n",
       "5  W3  ~  Xl   1.000000e+00  0 NA NA      1        1      \n",
       "6  W4  ~  Xl   1.000000e+00  0 NA NA      1        1      \n",
       "7  Sl  =~ Xl   1.000000e+00  0 NA NA      1        1      \n",
       "8  Sl  =~ Z1   1.000000e+00  0 NA NA      1        1      \n",
       "9  Sl  =~ Z2   1.000000e+00  0 NA NA      1        1      \n",
       "10 Y1  ~  Sl  -5.013969e+04 NA NA NA     NA       NA      \n",
       "11 Y2  ~  Sl  -5.008239e+04 NA NA NA     NA       NA      \n",
       "12 Y3  ~  Sl  -5.012076e+04 NA NA NA     NA       NA      \n",
       "13 Z1  ~~ Z1   1.517355e+00 NA NA NA     NA       NA      \n",
       "14 Z2  ~~ Z2  -1.495842e+02 NA NA NA     NA       NA      \n",
       "15 W1  ~~ W1   1.583656e+00 NA NA NA     NA       NA      \n",
       "16 W2  ~~ W2   1.555718e+00 NA NA NA     NA       NA      \n",
       "17 W3  ~~ W3   1.574713e+00 NA NA NA     NA       NA      \n",
       "18 W4  ~~ W4   1.572310e+00 NA NA NA     NA       NA      \n",
       "19 Y1  ~~ Y1   9.449065e+03 NA NA NA     NA       NA      \n",
       "20 Y2  ~~ Y2   9.427715e+03 NA NA NA     NA       NA      \n",
       "21 Y3  ~~ Y3   9.442074e+03 NA NA NA     NA       NA      \n",
       "22 Xl  ~~ Xl   1.540572e-02 NA NA NA     NA       NA      \n",
       "23 Sl  ~~ Sl  -3.614910e-06 NA NA NA     NA       NA      \n",
       "24 W1  ~~ W2   1.533910e+00 NA NA NA     NA       NA      \n",
       "25 W1  ~~ W3   1.537922e+00 NA NA NA     NA       NA      \n",
       "26 W1  ~~ W4   1.534279e+00 NA NA NA     NA       NA      \n",
       "27 W1  ~~ Y1   1.831594e+01 NA NA NA     NA       NA      \n",
       "28 W1  ~~ Y2   1.829617e+01 NA NA NA     NA       NA      \n",
       "29 W1  ~~ Y3   1.830570e+01 NA NA NA     NA       NA      \n",
       "30 W2  ~~ W3   1.530534e+00 NA NA NA     NA       NA      \n",
       "31 W2  ~~ W4   1.532390e+00 NA NA NA     NA       NA      \n",
       "32 W2  ~~ Y1   1.831280e+01 NA NA NA     NA       NA      \n",
       "33 W2  ~~ Y2   1.829696e+01 NA NA NA     NA       NA      \n",
       "34 W2  ~~ Y3   1.830682e+01 NA NA NA     NA       NA      \n",
       "35 W3  ~~ W4   1.536834e+00 NA NA NA     NA       NA      \n",
       "36 W3  ~~ Y1   1.867649e+01 NA NA NA     NA       NA      \n",
       "37 W3  ~~ Y2   1.865395e+01 NA NA NA     NA       NA      \n",
       "38 W3  ~~ Y3   1.866652e+01 NA NA NA     NA       NA      \n",
       "39 W4  ~~ Y1   1.844548e+01 NA NA NA     NA       NA      \n",
       "40 W4  ~~ Y2   1.842872e+01 NA NA NA     NA       NA      \n",
       "41 W4  ~~ Y3   1.843657e+01 NA NA NA     NA       NA      \n",
       "42 Y1  ~~ Y2   9.438374e+03 NA NA NA     NA       NA      \n",
       "43 Y1  ~~ Y3   9.445559e+03 NA NA NA     NA       NA      \n",
       "44 Y2  ~~ Y3   9.434882e+03 NA NA NA     NA       NA      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod <- \"\n",
    "Xl =~ Z1 + Z2\n",
    "W1 ~ 1*Xl\n",
    "W2 ~ 1*Xl\n",
    "W3 ~ 1*Xl\n",
    "W4 ~ 1*Xl\n",
    "Sl =~ 1*s(Xl) + 1*s(Z1) + 1*s(Z2)\n",
    "Y1 ~ Sl\n",
    "Y2 ~ Sl\n",
    "Y3 ~ Sl\n",
    "\"\n",
    "\n",
    "fit_lavaan <- sem(mod, data = data)\n",
    "parameterEstimates(fit_lavaan)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## blavaan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/Users/nescoba/Library/R/arm64/4.2/library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "also installing the dependencies ‘CompQuadForm’, ‘nonnest2’, ‘tmvnsim’\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/gb/chvh9g355qqf4q5rw11d1m55xdk3f1/T//Rtmp9Kc9YD/downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is blavaan 0.4-7\n",
      "\n",
      "On multicore systems, we suggest use of future::plan(\"multicore\") or\n",
      "  future::plan(\"multisession\") for faster post-MCMC computations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# install.packages(\"blavaan\")\n",
    "library(blavaan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "as(<lMatrix>, \"dgCMatrix\") is deprecated since Matrix 1.5-0; do as(as(as(., \"dMatrix\"), \"generalMatrix\"), \"CsparseMatrix\") instead\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAMPLING FOR MODEL 'stanmarg' NOW (CHAIN 1).\n",
      "Chain 1: \n",
      "Chain 1: Gradient evaluation took 0.000392 seconds\n",
      "Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 3.92 seconds.\n",
      "Chain 1: Adjust your expectations accordingly!\n",
      "Chain 1: \n",
      "Chain 1: \n",
      "Chain 1: Iteration:    1 / 1500 [  0%]  (Warmup)\n",
      "Chain 1: Iteration:  150 / 1500 [ 10%]  (Warmup)\n",
      "Chain 1: Iteration:  300 / 1500 [ 20%]  (Warmup)\n",
      "Chain 1: Iteration:  450 / 1500 [ 30%]  (Warmup)\n",
      "Chain 1: Iteration:  501 / 1500 [ 33%]  (Sampling)\n",
      "Chain 1: Iteration:  650 / 1500 [ 43%]  (Sampling)\n",
      "Chain 1: Iteration:  800 / 1500 [ 53%]  (Sampling)\n",
      "Chain 1: Iteration:  950 / 1500 [ 63%]  (Sampling)\n",
      "Chain 1: Iteration: 1100 / 1500 [ 73%]  (Sampling)\n",
      "Chain 1: Iteration: 1250 / 1500 [ 83%]  (Sampling)\n",
      "Chain 1: Iteration: 1400 / 1500 [ 93%]  (Sampling)\n",
      "Chain 1: Iteration: 1500 / 1500 [100%]  (Sampling)\n",
      "Chain 1: \n",
      "Chain 1:  Elapsed Time: 43.8254 seconds (Warm-up)\n",
      "Chain 1:                116.429 seconds (Sampling)\n",
      "Chain 1:                160.255 seconds (Total)\n",
      "Chain 1: \n",
      "\n",
      "SAMPLING FOR MODEL 'stanmarg' NOW (CHAIN 2).\n",
      "Chain 2: \n",
      "Chain 2: Gradient evaluation took 0.000144 seconds\n",
      "Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 1.44 seconds.\n",
      "Chain 2: Adjust your expectations accordingly!\n",
      "Chain 2: \n",
      "Chain 2: \n",
      "Chain 2: Iteration:    1 / 1500 [  0%]  (Warmup)\n",
      "Chain 2: Iteration:  150 / 1500 [ 10%]  (Warmup)\n",
      "Chain 2: Iteration:  300 / 1500 [ 20%]  (Warmup)\n",
      "Chain 2: Iteration:  450 / 1500 [ 30%]  (Warmup)\n",
      "Chain 2: Iteration:  501 / 1500 [ 33%]  (Sampling)\n",
      "Chain 2: Iteration:  650 / 1500 [ 43%]  (Sampling)\n",
      "Chain 2: Iteration:  800 / 1500 [ 53%]  (Sampling)\n",
      "Chain 2: Iteration:  950 / 1500 [ 63%]  (Sampling)\n",
      "Chain 2: Iteration: 1100 / 1500 [ 73%]  (Sampling)\n",
      "Chain 2: Iteration: 1250 / 1500 [ 83%]  (Sampling)\n",
      "Chain 2: Iteration: 1400 / 1500 [ 93%]  (Sampling)\n",
      "Chain 2: Iteration: 1500 / 1500 [100%]  (Sampling)\n",
      "Chain 2: \n",
      "Chain 2:  Elapsed Time: 42.7251 seconds (Warm-up)\n",
      "Chain 2:                115.488 seconds (Sampling)\n",
      "Chain 2:                158.213 seconds (Total)\n",
      "Chain 2: \n",
      "\n",
      "SAMPLING FOR MODEL 'stanmarg' NOW (CHAIN 3).\n",
      "Chain 3: \n",
      "Chain 3: Gradient evaluation took 0.000149 seconds\n",
      "Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 1.49 seconds.\n",
      "Chain 3: Adjust your expectations accordingly!\n",
      "Chain 3: \n",
      "Chain 3: \n",
      "Chain 3: Iteration:    1 / 1500 [  0%]  (Warmup)\n",
      "Chain 3: Iteration:  150 / 1500 [ 10%]  (Warmup)\n",
      "Chain 3: Iteration:  300 / 1500 [ 20%]  (Warmup)\n",
      "Chain 3: Iteration:  450 / 1500 [ 30%]  (Warmup)\n",
      "Chain 3: Iteration:  501 / 1500 [ 33%]  (Sampling)\n",
      "Chain 3: Iteration:  650 / 1500 [ 43%]  (Sampling)\n",
      "Chain 3: Iteration:  800 / 1500 [ 53%]  (Sampling)\n",
      "Chain 3: Iteration:  950 / 1500 [ 63%]  (Sampling)\n",
      "Chain 3: Iteration: 1100 / 1500 [ 73%]  (Sampling)\n",
      "Chain 3: Iteration: 1250 / 1500 [ 83%]  (Sampling)\n",
      "Chain 3: Iteration: 1400 / 1500 [ 93%]  (Sampling)\n",
      "Chain 3: Iteration: 1500 / 1500 [100%]  (Sampling)\n",
      "Chain 3: \n",
      "Chain 3:  Elapsed Time: 42.1102 seconds (Warm-up)\n",
      "Chain 3:                116.641 seconds (Sampling)\n",
      "Chain 3:                158.751 seconds (Total)\n",
      "Chain 3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“There were 20 divergent transitions after warmup. See\n",
      "https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n",
      "to find out why this is a problem and how to eliminate them.”\n",
      "Warning message:\n",
      "“There were 2977 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 10. See\n",
      "https://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded”\n",
      "Warning message:\n",
      "“Examine the pairs() plot to diagnose sampling problems\n",
      "”\n",
      "Warning message:\n",
      "“The largest R-hat is NA, indicating chains have not mixed.\n",
      "Running the chains for more iterations may help. See\n",
      "https://mc-stan.org/misc/warnings.html#r-hat”\n",
      "Warning message:\n",
      "“Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.\n",
      "Running the chains for more iterations may help. See\n",
      "https://mc-stan.org/misc/warnings.html#bulk-ess”\n",
      "Warning message:\n",
      "“Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.\n",
      "Running the chains for more iterations may help. See\n",
      "https://mc-stan.org/misc/warnings.html#tail-ess”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing posterior predictives...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“blavaan WARNING: As specified, the psi covariance matrix is neither diagonal nor unrestricted, so the actual prior might differ from the stated prior. See\n",
      " https://arxiv.org/abs/2301.08667”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blavaan (0.4-7) results of 1000 samples after 500 adapt/burnin iterations\n",
      "\n",
      "  Number of observations                           100\n",
      "\n",
      "  Statistic                                 MargLogLik         PPP\n",
      "  Value                                             NA       0.000\n",
      "\n",
      "Latent Variables:\n",
      "                   Estimate  Post.SD pi.lower pi.upper     Rhat    Prior       \n",
      "  Xl =~                                                                        \n",
      "    Z1                1.000                                                    \n",
      "    Z2                3.545    1.061    2.126    6.271    1.070    normal(0,10)\n",
      "  Sl =~                                                                        \n",
      "    Xl                1.000                                                    \n",
      "    Z1                1.000                                                    \n",
      "    Z2                1.000                                                    \n",
      "\n",
      "Regressions:\n",
      "                   Estimate  Post.SD pi.lower pi.upper     Rhat    Prior       \n",
      "  W1 ~                                                                         \n",
      "    Xl                1.000                                                    \n",
      "  W2 ~                                                                         \n",
      "    Xl                1.000                                                    \n",
      "  W3 ~                                                                         \n",
      "    Xl                1.000                                                    \n",
      "  W4 ~                                                                         \n",
      "    Xl                1.000                                                    \n",
      "  Y1 ~                                                                         \n",
      "    Sl               -0.242    8.330  -17.338   15.245    1.032    normal(0,10)\n",
      "  Y2 ~                                                                         \n",
      "    Sl               -1.130    8.260  -18.553   14.307    1.032    normal(0,10)\n",
      "  Y3 ~                                                                         \n",
      "    Sl               -0.185    7.680  -15.624   15.017    1.088    normal(0,10)\n",
      "\n",
      "Covariances:\n",
      "                   Estimate  Post.SD pi.lower pi.upper     Rhat    Prior       \n",
      " .W1 ~~                                                                        \n",
      "   .W2                0.898    0.117    0.705    1.155    1.068       beta(1,1)\n",
      "   .W3                0.882    0.114    0.692    1.140    1.069       beta(1,1)\n",
      "   .W4                0.897    0.118    0.701    1.160    1.067       beta(1,1)\n",
      "   .Y1                8.016    1.374    5.425   10.754    1.140       beta(1,1)\n",
      "   .Y2                8.012    1.373    5.410   10.748    1.140       beta(1,1)\n",
      "   .Y3                8.011    1.373    5.425   10.755    1.140       beta(1,1)\n",
      " .W2 ~~                                                                        \n",
      "   .W3                0.897    0.116    0.704    1.150    1.069       beta(1,1)\n",
      "   .W4                0.918    0.120    0.719    1.186    1.068       beta(1,1)\n",
      "   .Y1                8.233    1.386    5.687   10.994    1.138       beta(1,1)\n",
      "   .Y2                8.234    1.385    5.690   10.990    1.138       beta(1,1)\n",
      "   .Y3                8.234    1.386    5.677   10.994    1.138       beta(1,1)\n",
      " .W3 ~~                                                                        \n",
      "   .W4                0.903    0.117    0.709    1.167    1.069       beta(1,1)\n",
      "   .Y1                8.292    1.374    5.816   11.046    1.136       beta(1,1)\n",
      "   .Y2                8.285    1.373    5.798   11.030    1.136       beta(1,1)\n",
      "   .Y3                8.288    1.374    5.806   11.041    1.136       beta(1,1)\n",
      " .W4 ~~                                                                        \n",
      "   .Y1                8.392    1.394    5.824   11.251    1.135       beta(1,1)\n",
      "   .Y2                8.391    1.393    5.821   11.244    1.135       beta(1,1)\n",
      "   .Y3                8.389    1.393    5.832   11.240    1.135       beta(1,1)\n",
      " .Y1 ~~                                                                        \n",
      "   .Y2              214.110   25.795  170.113  267.053    1.032       beta(1,1)\n",
      "   .Y3              214.205   25.816  170.143  267.310    1.032       beta(1,1)\n",
      " .Y2 ~~                                                                        \n",
      "   .Y3              214.100   25.791  170.113  267.198    1.032       beta(1,1)\n",
      "\n",
      "Variances:\n",
      "                   Estimate  Post.SD pi.lower pi.upper     Rhat    Prior       \n",
      "   .Z1                1.031    0.152    0.772    1.357    1.003 gamma(1,.5)[sd]\n",
      "   .Z2                0.062    0.101    0.000    0.356    1.042 gamma(1,.5)[sd]\n",
      "   .W1                0.934    0.119    0.735    1.200    1.063 gamma(1,.5)[sd]\n",
      "   .W2                0.947    0.121    0.746    1.215    1.065 gamma(1,.5)[sd]\n",
      "   .W3                0.928    0.117    0.734    1.182    1.066 gamma(1,.5)[sd]\n",
      "   .W4                0.964    0.124    0.759    1.242    1.066 gamma(1,.5)[sd]\n",
      "   .Y1              214.226   25.821  170.307  267.449    1.032 gamma(1,.5)[sd]\n",
      "   .Y2              214.014   25.771  170.111  266.843    1.032 gamma(1,.5)[sd]\n",
      "   .Y3              214.203   25.812  170.158  267.543    1.032 gamma(1,.5)[sd]\n",
      "   .Xl                0.065    0.037    0.014    0.147    1.067 gamma(1,.5)[sd]\n",
      "    Sl                0.000    0.002             0.002    1.006 gamma(1,.5)[sd]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit <- bsem(mod, data = data)\n",
    "summary(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inference for Stan model: stanmarg.\n",
       "3 chains, each with iter=1500; warmup=500; thin=1; \n",
       "post-warmup draws per chain=1000, total post-warmup draws=3000.\n",
       "\n",
       "                  mean se_mean    sd    2.5%     25%     50%     75%   97.5%\n",
       "ly_sign[1]        3.54    0.16  1.06    2.13    2.76    3.30    4.10    6.27\n",
       "bet_sign[1]      -0.24    0.81  8.33  -17.34   -5.33   -0.06    5.10   15.25\n",
       "bet_sign[2]      -1.13    0.69  8.26  -18.55   -6.24   -0.79    4.23   14.31\n",
       "bet_sign[3]      -0.18    1.31  7.68  -15.62   -5.02   -0.24    4.70   15.02\n",
       "Theta_var[1]      1.03    0.01  0.15    0.77    0.92    1.02    1.13    1.36\n",
       "Theta_var[2]      0.06    0.01  0.10    0.00    0.01    0.02    0.07    0.36\n",
       "Psi_cov[1]        0.90    0.02  0.12    0.71    0.81    0.89    0.97    1.15\n",
       "Psi_cov[2]        0.88    0.02  0.11    0.69    0.80    0.87    0.95    1.14\n",
       "Psi_cov[3]        0.90    0.02  0.12    0.70    0.81    0.89    0.97    1.16\n",
       "Psi_cov[4]        8.02    0.37  1.37    5.42    7.05    7.95    8.96   10.75\n",
       "Psi_cov[5]        8.01    0.37  1.37    5.41    7.04    7.94    8.97   10.75\n",
       "Psi_cov[6]        8.01    0.37  1.37    5.43    7.04    7.95    8.96   10.75\n",
       "Psi_cov[7]        0.90    0.02  0.12    0.70    0.81    0.89    0.97    1.15\n",
       "Psi_cov[8]        0.92    0.02  0.12    0.72    0.83    0.91    0.99    1.19\n",
       "Psi_cov[9]        8.23    0.35  1.39    5.69    7.25    8.15    9.18   10.99\n",
       "Psi_cov[10]       8.23    0.35  1.39    5.69    7.25    8.15    9.18   10.99\n",
       "Psi_cov[11]       8.23    0.35  1.39    5.68    7.25    8.16    9.18   10.99\n",
       "Psi_cov[12]       0.90    0.02  0.12    0.71    0.82    0.89    0.97    1.17\n",
       "Psi_cov[13]       8.29    0.34  1.37    5.82    7.28    8.24    9.21   11.05\n",
       "Psi_cov[14]       8.29    0.34  1.37    5.80    7.28    8.23    9.21   11.03\n",
       "Psi_cov[15]       8.29    0.34  1.37    5.81    7.28    8.24    9.21   11.04\n",
       "Psi_cov[16]       8.39    0.36  1.39    5.82    7.39    8.31    9.32   11.25\n",
       "Psi_cov[17]       8.39    0.35  1.39    5.82    7.40    8.31    9.32   11.24\n",
       "Psi_cov[18]       8.39    0.36  1.39    5.83    7.39    8.31    9.33   11.24\n",
       "Psi_cov[19]     214.11    2.50 25.80  170.11  195.14  211.91  231.26  267.05\n",
       "Psi_cov[20]     214.21    2.51 25.82  170.14  195.15  212.08  231.36  267.31\n",
       "Psi_cov[21]     214.10    2.50 25.79  170.11  195.07  211.80  231.26  267.20\n",
       "Psi_var[1]        0.07    0.01  0.04    0.01    0.04    0.06    0.09    0.15\n",
       "Psi_var[2]        0.00    0.00  0.00    0.00    0.00    0.00    0.00    0.00\n",
       "Psi_var[3]        0.93    0.02  0.12    0.74    0.85    0.92    1.01    1.20\n",
       "Psi_var[4]        0.95    0.02  0.12    0.75    0.86    0.94    1.03    1.21\n",
       "Psi_var[5]        0.93    0.02  0.12    0.73    0.84    0.92    1.00    1.18\n",
       "Psi_var[6]        0.96    0.02  0.12    0.76    0.87    0.95    1.04    1.24\n",
       "Psi_var[7]      214.23    2.51 25.82  170.31  195.14  212.08  231.45  267.45\n",
       "Psi_var[8]      214.01    2.50 25.77  170.11  195.06  211.72  231.27  266.84\n",
       "Psi_var[9]      214.20    2.50 25.81  170.16  195.03  212.00  231.31  267.54\n",
       "log_lik[1]     -306.15    0.33  5.16 -317.04 -309.45 -305.73 -302.43 -296.81\n",
       "log_lik_sat[1]  238.95    0.33  5.16  229.62  235.24  238.53  242.25  249.85\n",
       "ppp               0.00     NaN  0.00    0.00    0.00    0.00    0.00    0.00\n",
       "lp__           -430.03    0.25  4.73 -440.15 -433.01 -429.60 -426.77 -421.65\n",
       "               n_eff Rhat\n",
       "ly_sign[1]        43 1.07\n",
       "bet_sign[1]      106 1.03\n",
       "bet_sign[2]      144 1.03\n",
       "bet_sign[3]       34 1.09\n",
       "Theta_var[1]     698 1.00\n",
       "Theta_var[2]     162 1.04\n",
       "Psi_cov[1]        50 1.07\n",
       "Psi_cov[2]        44 1.07\n",
       "Psi_cov[3]        50 1.07\n",
       "Psi_cov[4]        14 1.14\n",
       "Psi_cov[5]        14 1.14\n",
       "Psi_cov[6]        14 1.14\n",
       "Psi_cov[7]        49 1.07\n",
       "Psi_cov[8]        50 1.07\n",
       "Psi_cov[9]        16 1.14\n",
       "Psi_cov[10]       16 1.14\n",
       "Psi_cov[11]       16 1.14\n",
       "Psi_cov[12]       47 1.07\n",
       "Psi_cov[13]       16 1.14\n",
       "Psi_cov[14]       16 1.14\n",
       "Psi_cov[15]       16 1.14\n",
       "Psi_cov[16]       15 1.14\n",
       "Psi_cov[17]       15 1.14\n",
       "Psi_cov[18]       15 1.14\n",
       "Psi_cov[19]      106 1.03\n",
       "Psi_cov[20]      106 1.03\n",
       "Psi_cov[21]      106 1.03\n",
       "Psi_var[1]        51 1.07\n",
       "Psi_var[2]       398 1.01\n",
       "Psi_var[3]        54 1.06\n",
       "Psi_var[4]        51 1.07\n",
       "Psi_var[5]        47 1.07\n",
       "Psi_var[6]        50 1.07\n",
       "Psi_var[7]       106 1.03\n",
       "Psi_var[8]       106 1.03\n",
       "Psi_var[9]       106 1.03\n",
       "log_lik[1]       248 1.01\n",
       "log_lik_sat[1]   248 1.01\n",
       "ppp              NaN  NaN\n",
       "lp__             365 1.01\n",
       "\n",
       "Samples were drawn using NUTS(diag_e) at Sat Mar  4 17:58:00 2023.\n",
       "For each parameter, n_eff is a crude measure of effective sample size,\n",
       "and Rhat is the potential scale reduction factor on split chains (at \n",
       "convergence, Rhat=1)."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "blavInspect(fit, \"mcobj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "save(file = \"paper.RData\", list = ls())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
